{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np0gOsWT55bs"
      },
      "source": [
        "import os\n",
        "import trimesh\n",
        "import numpy as np\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import kaolin as kal\n",
        "import kaolin.ops.conversions as tfs\n",
        "from kaolin.io.modelnet import ModelNet\n",
        "from kaolin.ops.gcn import GraphConv\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH-lNIiS6ajB"
      },
      "source": [
        "#Downloading dataset\n",
        "directory = tf.keras.utils.get_file(\n",
        "    \"modelnet.zip\",\n",
        "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
        "    extract=True\n",
        ")\n",
        "directory = os.path.join(os.path.dirname(directory), \"ModelNet10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8X0dcyh7NLZ"
      },
      "source": [
        "#Data observation\n",
        "data1 = trimesh.load(os.path.join(directory, \"monitor/train/monitor_0005.off\"))\n",
        "data1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWPp813J-Afl"
      },
      "source": [
        "#Data observation\n",
        "data2 = trimesh.load(os.path.join(directory, \"sofa/train/sofa_0005.off\"))\n",
        "data2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc8QUJ-p-UPn"
      },
      "source": [
        "#Data observation\n",
        "data3 = trimesh.load(os.path.join(directory, \"bathtub/train/bathtub_0005.off\"))\n",
        "data3.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCsLXUN__i_w"
      },
      "source": [
        "#Useful Parameters\n",
        "data_path = os.path.join(os.path.dirname(directory), \"ModelNet10\")\n",
        "obj_categories = ['monitor', 'sofa', 'bed','bathtub', 'table']\n",
        "number_of_points = 2048\n",
        "number_of_batch_size = 32\n",
        "rate = 0.001\n",
        "total_epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeNFbb4lBOtk"
      },
      "source": [
        "training_loader = DataLoader(ModelNet(data_path, \n",
        "                                      categories=obj_categories, \n",
        "                                      split='train'), \n",
        "                             batch_size=number_of_batch_size, \n",
        "                             shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKt3YV9IB3dU"
      },
      "source": [
        "validating_loader = DataLoader(ModelNet(data_path, \n",
        "                                        categories=obj_categories, \n",
        "                                        split='test'), \n",
        "                               batch_size=number_of_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp2O2SR4CTR8"
      },
      "source": [
        "#Building the model\n",
        "model = GraphConv(len(obj_categories), 5)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=rate)\n",
        "entropy_loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYpHm9JzFNjR"
      },
      "source": [
        "#Training the model\n",
        "\n",
        "for epoch in range(total_epochs):\n",
        "\n",
        "    print('\\nEpoch: {epoch}\\n')\n",
        "\n",
        "    training_loss = 0.\n",
        "    training_accuracy = 0.\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index, (value, dicts) in enumerate(tqdm(training_loader)):\n",
        "        parti_category = dicts['category']\n",
        "        prediction = model(value)\n",
        "        loss = criterion(prediction, parti_category.view(-1))\n",
        "        training_loss += loss.item()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        #Calculating accuracy\n",
        "        lbl_prediction = torch.argmax(prediction, dim=1)\n",
        "        training_accuracy += torch.mean((lbl_prediction == parti_category.view(-1)).float()).item()\n",
        "\n",
        "    #Displying trainig loss and accuracy\n",
        "    print('Training loss:', training_loss / len(training_loader))\n",
        "    print('Training accuracy:', training_accuracy / len(training_loader))\n",
        "\n",
        "    validation_loss = 0.\n",
        "    validation_accuracy = 0.\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, (value, dicts) in enumerate(tqdm(validating_loader)):\n",
        "            parti_category = dicts['category']\n",
        "            prediction = model(value)\n",
        "            loss = criterion(prediction, parti_category.view(-1))\n",
        "            validation_loss += loss.item()\n",
        "\n",
        "            #Calculating accuracy\n",
        "            lbl_prediction = torch.argmax(prediction, dim=1)\n",
        "            validation_accuracy += torch.mean((lbl_prediction == parti_category.view(-1)).float()).item()\n",
        "\n",
        "    #Displaying validation loss and accuracy\n",
        "    print('Validation loss:', validation_loss / len(validating_loader))\n",
        "    print('Validation accuracy:', validation_accuracy / len(validating_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGkuhslILmdi"
      },
      "source": [
        "#Evaluating the trained model on test datasets\n",
        "\n",
        "testing_loader = DataLoader(ModelNet(data_path, \n",
        "                                     categories=obj_categories, \n",
        "                                     split='test'), \n",
        "                            shuffle=True, \n",
        "                            batch_size=number_of_batch_size)\n",
        "\n",
        "value, dicts = next(iter(testing_loader))\n",
        "parti_category = dicts['category']\n",
        "prediction = model(value)\n",
        "lbl_prediction = torch.max(prediction, axis=1)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWpncfnXNlsq"
      },
      "source": [
        "#Displaying results\n",
        "\n",
        "testIndex = 0 #We can enter the test index from 0..<number_of_batch_size\n",
        "lbl = obj_categories[parti_category[testIndex].item()]\n",
        "pred = obj_categories[lbl_prediction[testIndex]]\n",
        "\n",
        "fig = plt.figure()\n",
        "sub_plot = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "\n",
        "\n",
        "for index, point in enumerate(pointclouds):\n",
        "    color = 'g'\n",
        "    if pred == lbl:\n",
        "      color = 'g'\n",
        "    else:\n",
        "      color = 'r'\n",
        "    sub_plot.scatter(point[:, 0], point[:, 1], point[:, 2], c=color, s=3)\n",
        "\n",
        "sub_plot.set_title('Original Image: {0}\\nPredicted Image: {1}'.format(lbl, pred))\n",
        "sub_plot.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}